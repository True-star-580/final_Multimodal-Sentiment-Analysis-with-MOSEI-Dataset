{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVua-cjxDnkB",
        "outputId": "e34fa109-8e37-4119-a5cf-6dba81092fa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Multimodal-Sentiment-Analysis-with-MOSEI-Dataset' already exists and is not an empty directory.\n",
            "/content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/JugalGajjar/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset.git\n",
        "%cd Multimodal-Sentiment-Analysis-with-MOSEI-Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt -q"
      ],
      "metadata": {
        "id": "HPHz7v-RD5yB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2Viyq1QEGdB",
        "outputId": "2a05b562-9431-49c0-e111-43483485c318"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-14 22:14:15,607 - numexpr.utils - INFO - NumExpr defaulting to 12 threads.\n",
            "2025-08-14 22:14:18.678882: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-08-14 22:14:18.698310: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1755209658.720293   28842 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1755209658.726931   28842 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1755209658.744472   28842 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755209658.744506   28842 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755209658.744510   28842 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755209658.744512   28842 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-14 22:14:18.749385: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "===== Multimodal Sentiment Analysis Console =====\n",
            "1. Download and preprocess dataset\n",
            "2. Train a new model\n",
            "3. Evaluate a trained model\n",
            "4. Visualize training results\n",
            "5. Exit\n",
            "=================================================\n",
            "Enter your choice (1-5): 2\n",
            "Enter the path to the model checkpoint (.pt) or leave blank to train from scratch: \n",
            "Enter modalities (default: language,acoustic,visual): \n",
            "Enter batch size (default: 32): \n",
            "Enter number of epochs (default: 50): \n",
            "Enter hidden dimension (default: 256): \n",
            "Enter number of layers (default: 4): \n",
            "Enter number of heads (default: 8): \n",
            "Enter dropout rate (default: 0.3): \n",
            "Enter learning rate (default: 1e-4): \n",
            "Enter weight decay (default: 1e-5): \n",
            "Enter early stopping patience (default: 10): \n",
            "Enter gradient clipping value (default: 1.0): \n",
            "Enter random seed (default: 42): \n",
            "Enter log directory (default: logs/): \n",
            "Enter model save directory (default: models/): \n",
            "Enter device (cuda/mps/cpu/auto): \n",
            "2025-08-14 22:14:39,672 - root - INFO - Logging to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/logs/log.txt\n",
            "2025-08-14 22:14:39 - root - INFO - Logging to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/logs/log.txt\n",
            "2025-08-14 22:14:39,673 - root - INFO - All hyperparameters set.\n",
            "2025-08-14 22:14:39 - root - INFO - All hyperparameters set.\n",
            "2025-08-14 22:14:39,673 - root - INFO - Using device: cuda\n",
            "2025-08-14 22:14:39 - root - INFO - Using device: cuda\n",
            "2025-08-14 22:14:39,673 - root - INFO - Learning rate: 0.0001\n",
            "2025-08-14 22:14:39 - root - INFO - Learning rate: 0.0001\n",
            "2025-08-14 22:14:39,674 - root - INFO - \n",
            "Loading data...\n",
            "2025-08-14 22:14:39 - root - INFO - \n",
            "Loading data...\n",
            "2025-08-14 22:14:39,680 - src.data.dataset - INFO - Loaded 2370 samples for train split\n",
            "2025-08-14 22:14:39 - src.data.dataset - INFO - Loaded 2370 samples for train split\n",
            "2025-08-14 22:14:39,681 - src.data.dataset - INFO - Loaded 264 samples for val split\n",
            "2025-08-14 22:14:39 - src.data.dataset - INFO - Loaded 264 samples for val split\n",
            "2025-08-14 22:14:39,683 - src.data.dataset - INFO - Loaded 658 samples for test split\n",
            "2025-08-14 22:14:39 - src.data.dataset - INFO - Loaded 658 samples for test split\n",
            "2025-08-14 22:14:39,683 - root - INFO - \n",
            "Creating model...\n",
            "2025-08-14 22:14:39 - root - INFO - \n",
            "Creating model...\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n",
            "2025-08-14 22:14:39,821 - root - INFO - Model architecture:\n",
            "TransformerFusionModel(\n",
            "  (text_encoder): TransformerTextEncoder(\n",
            "    (input_projection): Linear(in_features=768, out_features=256, bias=True)\n",
            "    (transformer_encoder): TransformerEncoder(\n",
            "      (layers): ModuleList(\n",
            "        (0-3): 4 x TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (output_proj): Linear(in_features=256, out_features=1, bias=True)\n",
            ")\n",
            "2025-08-14 22:14:39 - root - INFO - Model architecture:\n",
            "TransformerFusionModel(\n",
            "  (text_encoder): TransformerTextEncoder(\n",
            "    (input_projection): Linear(in_features=768, out_features=256, bias=True)\n",
            "    (transformer_encoder): TransformerEncoder(\n",
            "      (layers): ModuleList(\n",
            "        (0-3): 4 x TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (output_proj): Linear(in_features=256, out_features=1, bias=True)\n",
            ")\n",
            "2025-08-14 22:14:39,823 - root - INFO - Logging to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/logs/multimodal_fusion.log/log.txt\n",
            "2025-08-14 22:14:39 - root - INFO - Logging to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/logs/multimodal_fusion.log/log.txt\n",
            "2025-08-14 22:14:39 - root - INFO - Logging to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/logs/multimodal_fusion.log/log.txt\n",
            "2025-08-14 22:14:39,823 - root - INFO - \n",
            "Starting training...\n",
            "2025-08-14 22:14:39 - root - INFO - \n",
            "Starting training...\n",
            "2025-08-14 22:14:39 - root - INFO - \n",
            "Starting training...\n",
            "2025-08-14 22:14:39,823 - src.training.trainer - INFO - Starting training for 50 epochs\n",
            "2025-08-14 22:14:39 - src.training.trainer - INFO - Starting training for 50 epochs\n",
            "2025-08-14 22:14:39 - src.training.trainer - INFO - Starting training for 50 epochs\n",
            "2025-08-14 22:14:39,823 - src.training.trainer - INFO - Model: TransformerFusionModel\n",
            "2025-08-14 22:14:39 - src.training.trainer - INFO - Model: TransformerFusionModel\n",
            "2025-08-14 22:14:39 - src.training.trainer - INFO - Model: TransformerFusionModel\n",
            "2025-08-14 22:14:39,823 - src.training.trainer - INFO - Device: cuda\n",
            "2025-08-14 22:14:39 - src.training.trainer - INFO - Device: cuda\n",
            "2025-08-14 22:14:39 - src.training.trainer - INFO - Device: cuda\n",
            "2025-08-14 22:14:39,823 - src.training.trainer - INFO - Train samples: 2370\n",
            "2025-08-14 22:14:39 - src.training.trainer - INFO - Train samples: 2370\n",
            "2025-08-14 22:14:39 - src.training.trainer - INFO - Train samples: 2370\n",
            "2025-08-14 22:14:39,823 - src.training.trainer - INFO - Validation samples: 264\n",
            "2025-08-14 22:14:39 - src.training.trainer - INFO - Validation samples: 264\n",
            "2025-08-14 22:14:39 - src.training.trainer - INFO - Validation samples: 264\n",
            "2025-08-14 22:14:39,823 - src.training.trainer - INFO - Test samples: 658\n",
            "2025-08-14 22:14:39 - src.training.trainer - INFO - Test samples: 658\n",
            "2025-08-14 22:14:39 - src.training.trainer - INFO - Test samples: 658\n",
            "Epoch 1: 100% 75/75 [00:01<00:00, 45.96it/s, loss=0.0184]\n",
            "2025-08-14 22:14:41,457 - src.training.trainer - INFO - Epoch 1 - Train loss: 0.0761\n",
            "2025-08-14 22:14:41 - src.training.trainer - INFO - Epoch 1 - Train loss: 0.0761\n",
            "2025-08-14 22:14:41 - src.training.trainer - INFO - Epoch 1 - Train loss: 0.0761\n",
            "2025-08-14 22:14:41,794 - src.training.trainer - INFO - Epoch 1 - Validation loss: 0.0156\n",
            "2025-08-14 22:14:41 - src.training.trainer - INFO - Epoch 1 - Validation loss: 0.0156\n",
            "2025-08-14 22:14:41 - src.training.trainer - INFO - Epoch 1 - Validation loss: 0.0156\n",
            "2025-08-14 22:14:41,794 - src.training.metrics - INFO - Epoch 1 - Val metrics:\n",
            "2025-08-14 22:14:41 - src.training.metrics - INFO - Epoch 1 - Val metrics:\n",
            "2025-08-14 22:14:41 - src.training.metrics - INFO - Epoch 1 - Val metrics:\n",
            "2025-08-14 22:14:41,794 - src.training.metrics - INFO -   MAE: 0.0935\n",
            "2025-08-14 22:14:41 - src.training.metrics - INFO -   MAE: 0.0935\n",
            "2025-08-14 22:14:41 - src.training.metrics - INFO -   MAE: 0.0935\n",
            "2025-08-14 22:14:41,794 - src.training.metrics - INFO -   Correlation: 0.4483\n",
            "2025-08-14 22:14:41 - src.training.metrics - INFO -   Correlation: 0.4483\n",
            "2025-08-14 22:14:41 - src.training.metrics - INFO -   Correlation: 0.4483\n",
            "2025-08-14 22:14:41,794 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:14:41 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:14:41 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:14:41,794 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:14:41 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:14:41 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:14:41,794 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:41 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:41 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:41,794 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:41 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:41 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:41,982 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "2025-08-14 22:14:41 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "2025-08-14 22:14:41 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "Epoch 2: 100% 75/75 [00:01<00:00, 67.78it/s, loss=0.0415]\n",
            "2025-08-14 22:14:43,090 - src.training.trainer - INFO - Epoch 2 - Train loss: 0.0293\n",
            "2025-08-14 22:14:43 - src.training.trainer - INFO - Epoch 2 - Train loss: 0.0293\n",
            "2025-08-14 22:14:43 - src.training.trainer - INFO - Epoch 2 - Train loss: 0.0293\n",
            "2025-08-14 22:14:43,391 - src.training.trainer - INFO - Epoch 2 - Validation loss: 0.0175\n",
            "2025-08-14 22:14:43 - src.training.trainer - INFO - Epoch 2 - Validation loss: 0.0175\n",
            "2025-08-14 22:14:43 - src.training.trainer - INFO - Epoch 2 - Validation loss: 0.0175\n",
            "2025-08-14 22:14:43,391 - src.training.metrics - INFO - Epoch 2 - Val metrics:\n",
            "2025-08-14 22:14:43 - src.training.metrics - INFO - Epoch 2 - Val metrics:\n",
            "2025-08-14 22:14:43 - src.training.metrics - INFO - Epoch 2 - Val metrics:\n",
            "2025-08-14 22:14:43,391 - src.training.metrics - INFO -   MAE: 0.0937\n",
            "2025-08-14 22:14:43 - src.training.metrics - INFO -   MAE: 0.0937\n",
            "2025-08-14 22:14:43 - src.training.metrics - INFO -   MAE: 0.0937\n",
            "2025-08-14 22:14:43,391 - src.training.metrics - INFO -   Correlation: 0.5237\n",
            "2025-08-14 22:14:43 - src.training.metrics - INFO -   Correlation: 0.5237\n",
            "2025-08-14 22:14:43 - src.training.metrics - INFO -   Correlation: 0.5237\n",
            "2025-08-14 22:14:43,391 - src.training.metrics - INFO -   Binary Accuracy: 0.9697\n",
            "2025-08-14 22:14:43 - src.training.metrics - INFO -   Binary Accuracy: 0.9697\n",
            "2025-08-14 22:14:43 - src.training.metrics - INFO -   Binary Accuracy: 0.9697\n",
            "2025-08-14 22:14:43,392 - src.training.metrics - INFO -   Binary F1: 0.9846\n",
            "2025-08-14 22:14:43 - src.training.metrics - INFO -   Binary F1: 0.9846\n",
            "2025-08-14 22:14:43 - src.training.metrics - INFO -   Binary F1: 0.9846\n",
            "2025-08-14 22:14:43,392 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:43 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:43 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:43,392 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:43 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:43 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:43,392 - src.training.trainer - INFO - No improvement for 1 evaluation steps.\n",
            "2025-08-14 22:14:43 - src.training.trainer - INFO - No improvement for 1 evaluation steps.\n",
            "2025-08-14 22:14:43 - src.training.trainer - INFO - No improvement for 1 evaluation steps.\n",
            "Epoch 3: 100% 75/75 [00:01<00:00, 67.69it/s, loss=0.0682]\n",
            "2025-08-14 22:14:44,501 - src.training.trainer - INFO - Epoch 3 - Train loss: 0.0259\n",
            "2025-08-14 22:14:44 - src.training.trainer - INFO - Epoch 3 - Train loss: 0.0259\n",
            "2025-08-14 22:14:44 - src.training.trainer - INFO - Epoch 3 - Train loss: 0.0259\n",
            "2025-08-14 22:14:44,787 - src.training.trainer - INFO - Epoch 3 - Validation loss: 0.0159\n",
            "2025-08-14 22:14:44 - src.training.trainer - INFO - Epoch 3 - Validation loss: 0.0159\n",
            "2025-08-14 22:14:44 - src.training.trainer - INFO - Epoch 3 - Validation loss: 0.0159\n",
            "2025-08-14 22:14:44,787 - src.training.metrics - INFO - Epoch 3 - Val metrics:\n",
            "2025-08-14 22:14:44 - src.training.metrics - INFO - Epoch 3 - Val metrics:\n",
            "2025-08-14 22:14:44 - src.training.metrics - INFO - Epoch 3 - Val metrics:\n",
            "2025-08-14 22:14:44,787 - src.training.metrics - INFO -   MAE: 0.0905\n",
            "2025-08-14 22:14:44 - src.training.metrics - INFO -   MAE: 0.0905\n",
            "2025-08-14 22:14:44 - src.training.metrics - INFO -   MAE: 0.0905\n",
            "2025-08-14 22:14:44,788 - src.training.metrics - INFO -   Correlation: 0.5327\n",
            "2025-08-14 22:14:44 - src.training.metrics - INFO -   Correlation: 0.5327\n",
            "2025-08-14 22:14:44 - src.training.metrics - INFO -   Correlation: 0.5327\n",
            "2025-08-14 22:14:44,788 - src.training.metrics - INFO -   Binary Accuracy: 0.9621\n",
            "2025-08-14 22:14:44 - src.training.metrics - INFO -   Binary Accuracy: 0.9621\n",
            "2025-08-14 22:14:44 - src.training.metrics - INFO -   Binary Accuracy: 0.9621\n",
            "2025-08-14 22:14:44,788 - src.training.metrics - INFO -   Binary F1: 0.9805\n",
            "2025-08-14 22:14:44 - src.training.metrics - INFO -   Binary F1: 0.9805\n",
            "2025-08-14 22:14:44 - src.training.metrics - INFO -   Binary F1: 0.9805\n",
            "2025-08-14 22:14:44,788 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:44 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:44 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:44,788 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:44 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:44 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:44,788 - src.training.trainer - INFO - No improvement for 2 evaluation steps.\n",
            "2025-08-14 22:14:44 - src.training.trainer - INFO - No improvement for 2 evaluation steps.\n",
            "2025-08-14 22:14:44 - src.training.trainer - INFO - No improvement for 2 evaluation steps.\n",
            "Epoch 4: 100% 75/75 [00:01<00:00, 68.20it/s, loss=0.0035]\n",
            "2025-08-14 22:14:45,889 - src.training.trainer - INFO - Epoch 4 - Train loss: 0.0220\n",
            "2025-08-14 22:14:45 - src.training.trainer - INFO - Epoch 4 - Train loss: 0.0220\n",
            "2025-08-14 22:14:45 - src.training.trainer - INFO - Epoch 4 - Train loss: 0.0220\n",
            "2025-08-14 22:14:46,176 - src.training.trainer - INFO - Epoch 4 - Validation loss: 0.0151\n",
            "2025-08-14 22:14:46 - src.training.trainer - INFO - Epoch 4 - Validation loss: 0.0151\n",
            "2025-08-14 22:14:46 - src.training.trainer - INFO - Epoch 4 - Validation loss: 0.0151\n",
            "2025-08-14 22:14:46,177 - src.training.metrics - INFO - Epoch 4 - Val metrics:\n",
            "2025-08-14 22:14:46 - src.training.metrics - INFO - Epoch 4 - Val metrics:\n",
            "2025-08-14 22:14:46 - src.training.metrics - INFO - Epoch 4 - Val metrics:\n",
            "2025-08-14 22:14:46,177 - src.training.metrics - INFO -   MAE: 0.0876\n",
            "2025-08-14 22:14:46 - src.training.metrics - INFO -   MAE: 0.0876\n",
            "2025-08-14 22:14:46 - src.training.metrics - INFO -   MAE: 0.0876\n",
            "2025-08-14 22:14:46,177 - src.training.metrics - INFO -   Correlation: 0.5517\n",
            "2025-08-14 22:14:46 - src.training.metrics - INFO -   Correlation: 0.5517\n",
            "2025-08-14 22:14:46 - src.training.metrics - INFO -   Correlation: 0.5517\n",
            "2025-08-14 22:14:46,177 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:14:46 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:14:46 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:14:46,177 - src.training.metrics - INFO -   Binary F1: 0.9825\n",
            "2025-08-14 22:14:46 - src.training.metrics - INFO -   Binary F1: 0.9825\n",
            "2025-08-14 22:14:46 - src.training.metrics - INFO -   Binary F1: 0.9825\n",
            "2025-08-14 22:14:46,177 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:46 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:46 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:46,177 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:46 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:46 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:46,338 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "2025-08-14 22:14:46 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "2025-08-14 22:14:46 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "Epoch 5: 100% 75/75 [00:01<00:00, 64.53it/s, loss=0.0130]\n",
            "2025-08-14 22:14:47,502 - src.training.trainer - INFO - Epoch 5 - Train loss: 0.0198\n",
            "2025-08-14 22:14:47 - src.training.trainer - INFO - Epoch 5 - Train loss: 0.0198\n",
            "2025-08-14 22:14:47 - src.training.trainer - INFO - Epoch 5 - Train loss: 0.0198\n",
            "2025-08-14 22:14:47,788 - src.training.trainer - INFO - Epoch 5 - Validation loss: 0.0151\n",
            "2025-08-14 22:14:47 - src.training.trainer - INFO - Epoch 5 - Validation loss: 0.0151\n",
            "2025-08-14 22:14:47 - src.training.trainer - INFO - Epoch 5 - Validation loss: 0.0151\n",
            "2025-08-14 22:14:47,788 - src.training.metrics - INFO - Epoch 5 - Val metrics:\n",
            "2025-08-14 22:14:47 - src.training.metrics - INFO - Epoch 5 - Val metrics:\n",
            "2025-08-14 22:14:47 - src.training.metrics - INFO - Epoch 5 - Val metrics:\n",
            "2025-08-14 22:14:47,788 - src.training.metrics - INFO -   MAE: 0.1019\n",
            "2025-08-14 22:14:47 - src.training.metrics - INFO -   MAE: 0.1019\n",
            "2025-08-14 22:14:47 - src.training.metrics - INFO -   MAE: 0.1019\n",
            "2025-08-14 22:14:47,788 - src.training.metrics - INFO -   Correlation: 0.5617\n",
            "2025-08-14 22:14:47 - src.training.metrics - INFO -   Correlation: 0.5617\n",
            "2025-08-14 22:14:47 - src.training.metrics - INFO -   Correlation: 0.5617\n",
            "2025-08-14 22:14:47,788 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:14:47 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:14:47 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:14:47,788 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:14:47 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:14:47 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:14:47,788 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:47 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:47 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:47,788 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:47 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:47 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:47,953 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "2025-08-14 22:14:47 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "2025-08-14 22:14:47 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "Epoch 6: 100% 75/75 [00:01<00:00, 67.67it/s, loss=0.0055]\n",
            "2025-08-14 22:14:49,152 - src.training.trainer - INFO - Epoch 6 - Train loss: 0.0207\n",
            "2025-08-14 22:14:49 - src.training.trainer - INFO - Epoch 6 - Train loss: 0.0207\n",
            "2025-08-14 22:14:49 - src.training.trainer - INFO - Epoch 6 - Train loss: 0.0207\n",
            "2025-08-14 22:14:49,448 - src.training.trainer - INFO - Epoch 6 - Validation loss: 0.0147\n",
            "2025-08-14 22:14:49 - src.training.trainer - INFO - Epoch 6 - Validation loss: 0.0147\n",
            "2025-08-14 22:14:49 - src.training.trainer - INFO - Epoch 6 - Validation loss: 0.0147\n",
            "2025-08-14 22:14:49,449 - src.training.metrics - INFO - Epoch 6 - Val metrics:\n",
            "2025-08-14 22:14:49 - src.training.metrics - INFO - Epoch 6 - Val metrics:\n",
            "2025-08-14 22:14:49 - src.training.metrics - INFO - Epoch 6 - Val metrics:\n",
            "2025-08-14 22:14:49,449 - src.training.metrics - INFO -   MAE: 0.1006\n",
            "2025-08-14 22:14:49 - src.training.metrics - INFO -   MAE: 0.1006\n",
            "2025-08-14 22:14:49 - src.training.metrics - INFO -   MAE: 0.1006\n",
            "2025-08-14 22:14:49,449 - src.training.metrics - INFO -   Correlation: 0.5653\n",
            "2025-08-14 22:14:49 - src.training.metrics - INFO -   Correlation: 0.5653\n",
            "2025-08-14 22:14:49 - src.training.metrics - INFO -   Correlation: 0.5653\n",
            "2025-08-14 22:14:49,449 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:14:49 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:14:49 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:14:49,449 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:14:49 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:14:49 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:14:49,449 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:49 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:49 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:49,449 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:49 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:49 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:49,615 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "2025-08-14 22:14:49 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "2025-08-14 22:14:49 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "Epoch 7: 100% 75/75 [00:01<00:00, 65.98it/s, loss=0.0262]\n",
            "2025-08-14 22:14:50,753 - src.training.trainer - INFO - Epoch 7 - Train loss: 0.0188\n",
            "2025-08-14 22:14:50 - src.training.trainer - INFO - Epoch 7 - Train loss: 0.0188\n",
            "2025-08-14 22:14:50 - src.training.trainer - INFO - Epoch 7 - Train loss: 0.0188\n",
            "2025-08-14 22:14:51,067 - src.training.trainer - INFO - Epoch 7 - Validation loss: 0.0134\n",
            "2025-08-14 22:14:51 - src.training.trainer - INFO - Epoch 7 - Validation loss: 0.0134\n",
            "2025-08-14 22:14:51 - src.training.trainer - INFO - Epoch 7 - Validation loss: 0.0134\n",
            "2025-08-14 22:14:51,068 - src.training.metrics - INFO - Epoch 7 - Val metrics:\n",
            "2025-08-14 22:14:51 - src.training.metrics - INFO - Epoch 7 - Val metrics:\n",
            "2025-08-14 22:14:51 - src.training.metrics - INFO - Epoch 7 - Val metrics:\n",
            "2025-08-14 22:14:51,068 - src.training.metrics - INFO -   MAE: 0.0933\n",
            "2025-08-14 22:14:51 - src.training.metrics - INFO -   MAE: 0.0933\n",
            "2025-08-14 22:14:51 - src.training.metrics - INFO -   MAE: 0.0933\n",
            "2025-08-14 22:14:51,068 - src.training.metrics - INFO -   Correlation: 0.5674\n",
            "2025-08-14 22:14:51 - src.training.metrics - INFO -   Correlation: 0.5674\n",
            "2025-08-14 22:14:51 - src.training.metrics - INFO -   Correlation: 0.5674\n",
            "2025-08-14 22:14:51,068 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:14:51 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:14:51 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:14:51,068 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:14:51 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:14:51 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:14:51,068 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:51 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:51 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:51,068 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:51 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:51 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:51,223 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "2025-08-14 22:14:51 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "2025-08-14 22:14:51 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "Epoch 8: 100% 75/75 [00:01<00:00, 66.97it/s, loss=0.0029]\n",
            "2025-08-14 22:14:52,344 - src.training.trainer - INFO - Epoch 8 - Train loss: 0.0176\n",
            "2025-08-14 22:14:52 - src.training.trainer - INFO - Epoch 8 - Train loss: 0.0176\n",
            "2025-08-14 22:14:52 - src.training.trainer - INFO - Epoch 8 - Train loss: 0.0176\n",
            "2025-08-14 22:14:52,636 - src.training.trainer - INFO - Epoch 8 - Validation loss: 0.0131\n",
            "2025-08-14 22:14:52 - src.training.trainer - INFO - Epoch 8 - Validation loss: 0.0131\n",
            "2025-08-14 22:14:52 - src.training.trainer - INFO - Epoch 8 - Validation loss: 0.0131\n",
            "2025-08-14 22:14:52,636 - src.training.metrics - INFO - Epoch 8 - Val metrics:\n",
            "2025-08-14 22:14:52 - src.training.metrics - INFO - Epoch 8 - Val metrics:\n",
            "2025-08-14 22:14:52 - src.training.metrics - INFO - Epoch 8 - Val metrics:\n",
            "2025-08-14 22:14:52,637 - src.training.metrics - INFO -   MAE: 0.0840\n",
            "2025-08-14 22:14:52 - src.training.metrics - INFO -   MAE: 0.0840\n",
            "2025-08-14 22:14:52 - src.training.metrics - INFO -   MAE: 0.0840\n",
            "2025-08-14 22:14:52,637 - src.training.metrics - INFO -   Correlation: 0.5572\n",
            "2025-08-14 22:14:52 - src.training.metrics - INFO -   Correlation: 0.5572\n",
            "2025-08-14 22:14:52 - src.training.metrics - INFO -   Correlation: 0.5572\n",
            "2025-08-14 22:14:52,637 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:14:52 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:14:52 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:14:52,637 - src.training.metrics - INFO -   Binary F1: 0.9826\n",
            "2025-08-14 22:14:52 - src.training.metrics - INFO -   Binary F1: 0.9826\n",
            "2025-08-14 22:14:52 - src.training.metrics - INFO -   Binary F1: 0.9826\n",
            "2025-08-14 22:14:52,637 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:52 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:52 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:52,637 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:52 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:52 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:52,793 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "2025-08-14 22:14:52 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "2025-08-14 22:14:52 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "Epoch 9: 100% 75/75 [00:01<00:00, 68.40it/s, loss=0.0161]\n",
            "2025-08-14 22:14:53,891 - src.training.trainer - INFO - Epoch 9 - Train loss: 0.0171\n",
            "2025-08-14 22:14:53 - src.training.trainer - INFO - Epoch 9 - Train loss: 0.0171\n",
            "2025-08-14 22:14:53 - src.training.trainer - INFO - Epoch 9 - Train loss: 0.0171\n",
            "2025-08-14 22:14:54,183 - src.training.trainer - INFO - Epoch 9 - Validation loss: 0.0234\n",
            "2025-08-14 22:14:54 - src.training.trainer - INFO - Epoch 9 - Validation loss: 0.0234\n",
            "2025-08-14 22:14:54 - src.training.trainer - INFO - Epoch 9 - Validation loss: 0.0234\n",
            "2025-08-14 22:14:54,184 - src.training.metrics - INFO - Epoch 9 - Val metrics:\n",
            "2025-08-14 22:14:54 - src.training.metrics - INFO - Epoch 9 - Val metrics:\n",
            "2025-08-14 22:14:54 - src.training.metrics - INFO - Epoch 9 - Val metrics:\n",
            "2025-08-14 22:14:54,184 - src.training.metrics - INFO -   MAE: 0.1167\n",
            "2025-08-14 22:14:54 - src.training.metrics - INFO -   MAE: 0.1167\n",
            "2025-08-14 22:14:54 - src.training.metrics - INFO -   MAE: 0.1167\n",
            "2025-08-14 22:14:54,184 - src.training.metrics - INFO -   Correlation: 0.5627\n",
            "2025-08-14 22:14:54 - src.training.metrics - INFO -   Correlation: 0.5627\n",
            "2025-08-14 22:14:54 - src.training.metrics - INFO -   Correlation: 0.5627\n",
            "2025-08-14 22:14:54,184 - src.training.metrics - INFO -   Binary Accuracy: 0.8485\n",
            "2025-08-14 22:14:54 - src.training.metrics - INFO -   Binary Accuracy: 0.8485\n",
            "2025-08-14 22:14:54 - src.training.metrics - INFO -   Binary Accuracy: 0.8485\n",
            "2025-08-14 22:14:54,184 - src.training.metrics - INFO -   Binary F1: 0.9167\n",
            "2025-08-14 22:14:54 - src.training.metrics - INFO -   Binary F1: 0.9167\n",
            "2025-08-14 22:14:54 - src.training.metrics - INFO -   Binary F1: 0.9167\n",
            "2025-08-14 22:14:54,184 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:54 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:54 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:54,184 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:54 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:54 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:54,184 - src.training.trainer - INFO - No improvement for 1 evaluation steps.\n",
            "2025-08-14 22:14:54 - src.training.trainer - INFO - No improvement for 1 evaluation steps.\n",
            "2025-08-14 22:14:54 - src.training.trainer - INFO - No improvement for 1 evaluation steps.\n",
            "Epoch 10: 100% 75/75 [00:01<00:00, 69.02it/s, loss=0.0423]\n",
            "2025-08-14 22:14:55,272 - src.training.trainer - INFO - Epoch 10 - Train loss: 0.0189\n",
            "2025-08-14 22:14:55 - src.training.trainer - INFO - Epoch 10 - Train loss: 0.0189\n",
            "2025-08-14 22:14:55 - src.training.trainer - INFO - Epoch 10 - Train loss: 0.0189\n",
            "2025-08-14 22:14:55,556 - src.training.trainer - INFO - Epoch 10 - Validation loss: 0.0138\n",
            "2025-08-14 22:14:55 - src.training.trainer - INFO - Epoch 10 - Validation loss: 0.0138\n",
            "2025-08-14 22:14:55 - src.training.trainer - INFO - Epoch 10 - Validation loss: 0.0138\n",
            "2025-08-14 22:14:55,556 - src.training.metrics - INFO - Epoch 10 - Val metrics:\n",
            "2025-08-14 22:14:55 - src.training.metrics - INFO - Epoch 10 - Val metrics:\n",
            "2025-08-14 22:14:55 - src.training.metrics - INFO - Epoch 10 - Val metrics:\n",
            "2025-08-14 22:14:55,556 - src.training.metrics - INFO -   MAE: 0.0849\n",
            "2025-08-14 22:14:55 - src.training.metrics - INFO -   MAE: 0.0849\n",
            "2025-08-14 22:14:55 - src.training.metrics - INFO -   MAE: 0.0849\n",
            "2025-08-14 22:14:55,556 - src.training.metrics - INFO -   Correlation: 0.5590\n",
            "2025-08-14 22:14:55 - src.training.metrics - INFO -   Correlation: 0.5590\n",
            "2025-08-14 22:14:55 - src.training.metrics - INFO -   Correlation: 0.5590\n",
            "2025-08-14 22:14:55,556 - src.training.metrics - INFO -   Binary Accuracy: 0.9583\n",
            "2025-08-14 22:14:55 - src.training.metrics - INFO -   Binary Accuracy: 0.9583\n",
            "2025-08-14 22:14:55 - src.training.metrics - INFO -   Binary Accuracy: 0.9583\n",
            "2025-08-14 22:14:55,556 - src.training.metrics - INFO -   Binary F1: 0.9786\n",
            "2025-08-14 22:14:55 - src.training.metrics - INFO -   Binary F1: 0.9786\n",
            "2025-08-14 22:14:55 - src.training.metrics - INFO -   Binary F1: 0.9786\n",
            "2025-08-14 22:14:55,556 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:55 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:55 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:55,557 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:55 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:55 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:55,557 - src.training.trainer - INFO - No improvement for 2 evaluation steps.\n",
            "2025-08-14 22:14:55 - src.training.trainer - INFO - No improvement for 2 evaluation steps.\n",
            "2025-08-14 22:14:55 - src.training.trainer - INFO - No improvement for 2 evaluation steps.\n",
            "Epoch 11: 100% 75/75 [00:01<00:00, 65.38it/s, loss=0.0484]\n",
            "2025-08-14 22:14:56,772 - src.training.trainer - INFO - Epoch 11 - Train loss: 0.0163\n",
            "2025-08-14 22:14:56 - src.training.trainer - INFO - Epoch 11 - Train loss: 0.0163\n",
            "2025-08-14 22:14:56 - src.training.trainer - INFO - Epoch 11 - Train loss: 0.0163\n",
            "2025-08-14 22:14:57,060 - src.training.trainer - INFO - Epoch 11 - Validation loss: 0.0158\n",
            "2025-08-14 22:14:57 - src.training.trainer - INFO - Epoch 11 - Validation loss: 0.0158\n",
            "2025-08-14 22:14:57 - src.training.trainer - INFO - Epoch 11 - Validation loss: 0.0158\n",
            "2025-08-14 22:14:57,061 - src.training.metrics - INFO - Epoch 11 - Val metrics:\n",
            "2025-08-14 22:14:57 - src.training.metrics - INFO - Epoch 11 - Val metrics:\n",
            "2025-08-14 22:14:57 - src.training.metrics - INFO - Epoch 11 - Val metrics:\n",
            "2025-08-14 22:14:57,061 - src.training.metrics - INFO -   MAE: 0.1057\n",
            "2025-08-14 22:14:57 - src.training.metrics - INFO -   MAE: 0.1057\n",
            "2025-08-14 22:14:57 - src.training.metrics - INFO -   MAE: 0.1057\n",
            "2025-08-14 22:14:57,061 - src.training.metrics - INFO -   Correlation: 0.5588\n",
            "2025-08-14 22:14:57 - src.training.metrics - INFO -   Correlation: 0.5588\n",
            "2025-08-14 22:14:57 - src.training.metrics - INFO -   Correlation: 0.5588\n",
            "2025-08-14 22:14:57,061 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:14:57 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:14:57 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:14:57,061 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:14:57 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:14:57 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:14:57,061 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:57 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:57 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:57,061 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:57 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:57 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:57,061 - src.training.trainer - INFO - No improvement for 3 evaluation steps.\n",
            "2025-08-14 22:14:57 - src.training.trainer - INFO - No improvement for 3 evaluation steps.\n",
            "2025-08-14 22:14:57 - src.training.trainer - INFO - No improvement for 3 evaluation steps.\n",
            "Epoch 12: 100% 75/75 [00:01<00:00, 67.99it/s, loss=0.0308]\n",
            "2025-08-14 22:14:58,166 - src.training.trainer - INFO - Epoch 12 - Train loss: 0.0166\n",
            "2025-08-14 22:14:58 - src.training.trainer - INFO - Epoch 12 - Train loss: 0.0166\n",
            "2025-08-14 22:14:58 - src.training.trainer - INFO - Epoch 12 - Train loss: 0.0166\n",
            "2025-08-14 22:14:58,454 - src.training.trainer - INFO - Epoch 12 - Validation loss: 0.0142\n",
            "2025-08-14 22:14:58 - src.training.trainer - INFO - Epoch 12 - Validation loss: 0.0142\n",
            "2025-08-14 22:14:58 - src.training.trainer - INFO - Epoch 12 - Validation loss: 0.0142\n",
            "2025-08-14 22:14:58,454 - src.training.metrics - INFO - Epoch 12 - Val metrics:\n",
            "2025-08-14 22:14:58 - src.training.metrics - INFO - Epoch 12 - Val metrics:\n",
            "2025-08-14 22:14:58 - src.training.metrics - INFO - Epoch 12 - Val metrics:\n",
            "2025-08-14 22:14:58,454 - src.training.metrics - INFO -   MAE: 0.0863\n",
            "2025-08-14 22:14:58 - src.training.metrics - INFO -   MAE: 0.0863\n",
            "2025-08-14 22:14:58 - src.training.metrics - INFO -   MAE: 0.0863\n",
            "2025-08-14 22:14:58,454 - src.training.metrics - INFO -   Correlation: 0.5577\n",
            "2025-08-14 22:14:58 - src.training.metrics - INFO -   Correlation: 0.5577\n",
            "2025-08-14 22:14:58 - src.training.metrics - INFO -   Correlation: 0.5577\n",
            "2025-08-14 22:14:58,455 - src.training.metrics - INFO -   Binary Accuracy: 0.9583\n",
            "2025-08-14 22:14:58 - src.training.metrics - INFO -   Binary Accuracy: 0.9583\n",
            "2025-08-14 22:14:58 - src.training.metrics - INFO -   Binary Accuracy: 0.9583\n",
            "2025-08-14 22:14:58,455 - src.training.metrics - INFO -   Binary F1: 0.9786\n",
            "2025-08-14 22:14:58 - src.training.metrics - INFO -   Binary F1: 0.9786\n",
            "2025-08-14 22:14:58 - src.training.metrics - INFO -   Binary F1: 0.9786\n",
            "2025-08-14 22:14:58,455 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:58 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:58 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:58,455 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:58 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:58 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:58,455 - src.training.trainer - INFO - No improvement for 4 evaluation steps.\n",
            "2025-08-14 22:14:58 - src.training.trainer - INFO - No improvement for 4 evaluation steps.\n",
            "2025-08-14 22:14:58 - src.training.trainer - INFO - No improvement for 4 evaluation steps.\n",
            "Epoch 13: 100% 75/75 [00:01<00:00, 69.02it/s, loss=0.0014]\n",
            "2025-08-14 22:14:59,543 - src.training.trainer - INFO - Epoch 13 - Train loss: 0.0151\n",
            "2025-08-14 22:14:59 - src.training.trainer - INFO - Epoch 13 - Train loss: 0.0151\n",
            "2025-08-14 22:14:59 - src.training.trainer - INFO - Epoch 13 - Train loss: 0.0151\n",
            "2025-08-14 22:14:59,827 - src.training.trainer - INFO - Epoch 13 - Validation loss: 0.0138\n",
            "2025-08-14 22:14:59 - src.training.trainer - INFO - Epoch 13 - Validation loss: 0.0138\n",
            "2025-08-14 22:14:59 - src.training.trainer - INFO - Epoch 13 - Validation loss: 0.0138\n",
            "2025-08-14 22:14:59,827 - src.training.metrics - INFO - Epoch 13 - Val metrics:\n",
            "2025-08-14 22:14:59 - src.training.metrics - INFO - Epoch 13 - Val metrics:\n",
            "2025-08-14 22:14:59 - src.training.metrics - INFO - Epoch 13 - Val metrics:\n",
            "2025-08-14 22:14:59,827 - src.training.metrics - INFO -   MAE: 0.0860\n",
            "2025-08-14 22:14:59 - src.training.metrics - INFO -   MAE: 0.0860\n",
            "2025-08-14 22:14:59 - src.training.metrics - INFO -   MAE: 0.0860\n",
            "2025-08-14 22:14:59,827 - src.training.metrics - INFO -   Correlation: 0.5559\n",
            "2025-08-14 22:14:59 - src.training.metrics - INFO -   Correlation: 0.5559\n",
            "2025-08-14 22:14:59 - src.training.metrics - INFO -   Correlation: 0.5559\n",
            "2025-08-14 22:14:59,827 - src.training.metrics - INFO -   Binary Accuracy: 0.9583\n",
            "2025-08-14 22:14:59 - src.training.metrics - INFO -   Binary Accuracy: 0.9583\n",
            "2025-08-14 22:14:59 - src.training.metrics - INFO -   Binary Accuracy: 0.9583\n",
            "2025-08-14 22:14:59,827 - src.training.metrics - INFO -   Binary F1: 0.9786\n",
            "2025-08-14 22:14:59 - src.training.metrics - INFO -   Binary F1: 0.9786\n",
            "2025-08-14 22:14:59 - src.training.metrics - INFO -   Binary F1: 0.9786\n",
            "2025-08-14 22:14:59,827 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:59 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:59 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:14:59,827 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:59 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:59 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:14:59,828 - src.training.trainer - INFO - No improvement for 5 evaluation steps.\n",
            "2025-08-14 22:14:59 - src.training.trainer - INFO - No improvement for 5 evaluation steps.\n",
            "2025-08-14 22:14:59 - src.training.trainer - INFO - No improvement for 5 evaluation steps.\n",
            "Epoch 14: 100% 75/75 [00:01<00:00, 67.97it/s, loss=0.0320]\n",
            "2025-08-14 22:15:00,932 - src.training.trainer - INFO - Epoch 14 - Train loss: 0.0165\n",
            "2025-08-14 22:15:00 - src.training.trainer - INFO - Epoch 14 - Train loss: 0.0165\n",
            "2025-08-14 22:15:00 - src.training.trainer - INFO - Epoch 14 - Train loss: 0.0165\n",
            "2025-08-14 22:15:01,228 - src.training.trainer - INFO - Epoch 14 - Validation loss: 0.0137\n",
            "2025-08-14 22:15:01 - src.training.trainer - INFO - Epoch 14 - Validation loss: 0.0137\n",
            "2025-08-14 22:15:01 - src.training.trainer - INFO - Epoch 14 - Validation loss: 0.0137\n",
            "2025-08-14 22:15:01,229 - src.training.metrics - INFO - Epoch 14 - Val metrics:\n",
            "2025-08-14 22:15:01 - src.training.metrics - INFO - Epoch 14 - Val metrics:\n",
            "2025-08-14 22:15:01 - src.training.metrics - INFO - Epoch 14 - Val metrics:\n",
            "2025-08-14 22:15:01,229 - src.training.metrics - INFO -   MAE: 0.0940\n",
            "2025-08-14 22:15:01 - src.training.metrics - INFO -   MAE: 0.0940\n",
            "2025-08-14 22:15:01 - src.training.metrics - INFO -   MAE: 0.0940\n",
            "2025-08-14 22:15:01,229 - src.training.metrics - INFO -   Correlation: 0.5591\n",
            "2025-08-14 22:15:01 - src.training.metrics - INFO -   Correlation: 0.5591\n",
            "2025-08-14 22:15:01 - src.training.metrics - INFO -   Correlation: 0.5591\n",
            "2025-08-14 22:15:01,229 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:15:01 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:15:01 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:15:01,229 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:15:01 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:15:01 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:15:01,229 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:01 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:01 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:01,229 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:15:01 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:15:01 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:15:01,229 - src.training.trainer - INFO - No improvement for 6 evaluation steps.\n",
            "2025-08-14 22:15:01 - src.training.trainer - INFO - No improvement for 6 evaluation steps.\n",
            "2025-08-14 22:15:01 - src.training.trainer - INFO - No improvement for 6 evaluation steps.\n",
            "Epoch 15: 100% 75/75 [00:01<00:00, 68.00it/s, loss=0.0147]\n",
            "2025-08-14 22:15:02,333 - src.training.trainer - INFO - Epoch 15 - Train loss: 0.0147\n",
            "2025-08-14 22:15:02 - src.training.trainer - INFO - Epoch 15 - Train loss: 0.0147\n",
            "2025-08-14 22:15:02 - src.training.trainer - INFO - Epoch 15 - Train loss: 0.0147\n",
            "2025-08-14 22:15:02,649 - src.training.trainer - INFO - Epoch 15 - Validation loss: 0.0129\n",
            "2025-08-14 22:15:02 - src.training.trainer - INFO - Epoch 15 - Validation loss: 0.0129\n",
            "2025-08-14 22:15:02 - src.training.trainer - INFO - Epoch 15 - Validation loss: 0.0129\n",
            "2025-08-14 22:15:02,649 - src.training.metrics - INFO - Epoch 15 - Val metrics:\n",
            "2025-08-14 22:15:02 - src.training.metrics - INFO - Epoch 15 - Val metrics:\n",
            "2025-08-14 22:15:02 - src.training.metrics - INFO - Epoch 15 - Val metrics:\n",
            "2025-08-14 22:15:02,649 - src.training.metrics - INFO -   MAE: 0.0899\n",
            "2025-08-14 22:15:02 - src.training.metrics - INFO -   MAE: 0.0899\n",
            "2025-08-14 22:15:02 - src.training.metrics - INFO -   MAE: 0.0899\n",
            "2025-08-14 22:15:02,649 - src.training.metrics - INFO -   Correlation: 0.5590\n",
            "2025-08-14 22:15:02 - src.training.metrics - INFO -   Correlation: 0.5590\n",
            "2025-08-14 22:15:02 - src.training.metrics - INFO -   Correlation: 0.5590\n",
            "2025-08-14 22:15:02,649 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:15:02 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:15:02 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:15:02,649 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:15:02 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:15:02 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:15:02,650 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:02 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:02 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:02,650 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:15:02 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:15:02 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:15:02,806 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "2025-08-14 22:15:02 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "2025-08-14 22:15:02 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "Epoch 16: 100% 75/75 [00:01<00:00, 63.33it/s, loss=0.0362]\n",
            "2025-08-14 22:15:04,082 - src.training.trainer - INFO - Epoch 16 - Train loss: 0.0149\n",
            "2025-08-14 22:15:04 - src.training.trainer - INFO - Epoch 16 - Train loss: 0.0149\n",
            "2025-08-14 22:15:04 - src.training.trainer - INFO - Epoch 16 - Train loss: 0.0149\n",
            "2025-08-14 22:15:04,375 - src.training.trainer - INFO - Epoch 16 - Validation loss: 0.0127\n",
            "2025-08-14 22:15:04 - src.training.trainer - INFO - Epoch 16 - Validation loss: 0.0127\n",
            "2025-08-14 22:15:04 - src.training.trainer - INFO - Epoch 16 - Validation loss: 0.0127\n",
            "2025-08-14 22:15:04,375 - src.training.metrics - INFO - Epoch 16 - Val metrics:\n",
            "2025-08-14 22:15:04 - src.training.metrics - INFO - Epoch 16 - Val metrics:\n",
            "2025-08-14 22:15:04 - src.training.metrics - INFO - Epoch 16 - Val metrics:\n",
            "2025-08-14 22:15:04,376 - src.training.metrics - INFO -   MAE: 0.0841\n",
            "2025-08-14 22:15:04 - src.training.metrics - INFO -   MAE: 0.0841\n",
            "2025-08-14 22:15:04 - src.training.metrics - INFO -   MAE: 0.0841\n",
            "2025-08-14 22:15:04,376 - src.training.metrics - INFO -   Correlation: 0.5545\n",
            "2025-08-14 22:15:04 - src.training.metrics - INFO -   Correlation: 0.5545\n",
            "2025-08-14 22:15:04 - src.training.metrics - INFO -   Correlation: 0.5545\n",
            "2025-08-14 22:15:04,376 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:15:04 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:15:04 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:15:04,376 - src.training.metrics - INFO -   Binary F1: 0.9826\n",
            "2025-08-14 22:15:04 - src.training.metrics - INFO -   Binary F1: 0.9826\n",
            "2025-08-14 22:15:04 - src.training.metrics - INFO -   Binary F1: 0.9826\n",
            "2025-08-14 22:15:04,376 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:04 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:04 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:04,376 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:15:04 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:15:04 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:15:04,532 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "2025-08-14 22:15:04 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "2025-08-14 22:15:04 - src.training.trainer - INFO - Saved best model to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "Epoch 17: 100% 75/75 [00:01<00:00, 65.17it/s, loss=0.0007]\n",
            "2025-08-14 22:15:05,684 - src.training.trainer - INFO - Epoch 17 - Train loss: 0.0148\n",
            "2025-08-14 22:15:05 - src.training.trainer - INFO - Epoch 17 - Train loss: 0.0148\n",
            "2025-08-14 22:15:05 - src.training.trainer - INFO - Epoch 17 - Train loss: 0.0148\n",
            "2025-08-14 22:15:05,977 - src.training.trainer - INFO - Epoch 17 - Validation loss: 0.0129\n",
            "2025-08-14 22:15:05 - src.training.trainer - INFO - Epoch 17 - Validation loss: 0.0129\n",
            "2025-08-14 22:15:05 - src.training.trainer - INFO - Epoch 17 - Validation loss: 0.0129\n",
            "2025-08-14 22:15:05,978 - src.training.metrics - INFO - Epoch 17 - Val metrics:\n",
            "2025-08-14 22:15:05 - src.training.metrics - INFO - Epoch 17 - Val metrics:\n",
            "2025-08-14 22:15:05 - src.training.metrics - INFO - Epoch 17 - Val metrics:\n",
            "2025-08-14 22:15:05,978 - src.training.metrics - INFO -   MAE: 0.0884\n",
            "2025-08-14 22:15:05 - src.training.metrics - INFO -   MAE: 0.0884\n",
            "2025-08-14 22:15:05 - src.training.metrics - INFO -   MAE: 0.0884\n",
            "2025-08-14 22:15:05,978 - src.training.metrics - INFO -   Correlation: 0.5533\n",
            "2025-08-14 22:15:05 - src.training.metrics - INFO -   Correlation: 0.5533\n",
            "2025-08-14 22:15:05 - src.training.metrics - INFO -   Correlation: 0.5533\n",
            "2025-08-14 22:15:05,978 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:15:05 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:15:05 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:15:05,978 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:15:05 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:15:05 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:15:05,978 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:05 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:05 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:05,978 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:15:05 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:15:05 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:15:05,978 - src.training.trainer - INFO - No improvement for 1 evaluation steps.\n",
            "2025-08-14 22:15:05 - src.training.trainer - INFO - No improvement for 1 evaluation steps.\n",
            "2025-08-14 22:15:05 - src.training.trainer - INFO - No improvement for 1 evaluation steps.\n",
            "Epoch 18: 100% 75/75 [00:01<00:00, 68.21it/s, loss=0.0433]\n",
            "2025-08-14 22:15:07,079 - src.training.trainer - INFO - Epoch 18 - Train loss: 0.0144\n",
            "2025-08-14 22:15:07 - src.training.trainer - INFO - Epoch 18 - Train loss: 0.0144\n",
            "2025-08-14 22:15:07 - src.training.trainer - INFO - Epoch 18 - Train loss: 0.0144\n",
            "2025-08-14 22:15:07,361 - src.training.trainer - INFO - Epoch 18 - Validation loss: 0.0156\n",
            "2025-08-14 22:15:07 - src.training.trainer - INFO - Epoch 18 - Validation loss: 0.0156\n",
            "2025-08-14 22:15:07 - src.training.trainer - INFO - Epoch 18 - Validation loss: 0.0156\n",
            "2025-08-14 22:15:07,361 - src.training.metrics - INFO - Epoch 18 - Val metrics:\n",
            "2025-08-14 22:15:07 - src.training.metrics - INFO - Epoch 18 - Val metrics:\n",
            "2025-08-14 22:15:07 - src.training.metrics - INFO - Epoch 18 - Val metrics:\n",
            "2025-08-14 22:15:07,361 - src.training.metrics - INFO -   MAE: 0.1033\n",
            "2025-08-14 22:15:07 - src.training.metrics - INFO -   MAE: 0.1033\n",
            "2025-08-14 22:15:07 - src.training.metrics - INFO -   MAE: 0.1033\n",
            "2025-08-14 22:15:07,361 - src.training.metrics - INFO -   Correlation: 0.5542\n",
            "2025-08-14 22:15:07 - src.training.metrics - INFO -   Correlation: 0.5542\n",
            "2025-08-14 22:15:07 - src.training.metrics - INFO -   Correlation: 0.5542\n",
            "2025-08-14 22:15:07,361 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:15:07 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:15:07 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:15:07,361 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:15:07 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:15:07 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:15:07,361 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:07 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:07 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:07,361 - src.training.metrics - INFO -   7-class F1: 0.9699\n",
            "2025-08-14 22:15:07 - src.training.metrics - INFO -   7-class F1: 0.9699\n",
            "2025-08-14 22:15:07 - src.training.metrics - INFO -   7-class F1: 0.9699\n",
            "2025-08-14 22:15:07,361 - src.training.trainer - INFO - No improvement for 2 evaluation steps.\n",
            "2025-08-14 22:15:07 - src.training.trainer - INFO - No improvement for 2 evaluation steps.\n",
            "2025-08-14 22:15:07 - src.training.trainer - INFO - No improvement for 2 evaluation steps.\n",
            "Epoch 19: 100% 75/75 [00:01<00:00, 67.33it/s, loss=0.0081]\n",
            "2025-08-14 22:15:08,477 - src.training.trainer - INFO - Epoch 19 - Train loss: 0.0142\n",
            "2025-08-14 22:15:08 - src.training.trainer - INFO - Epoch 19 - Train loss: 0.0142\n",
            "2025-08-14 22:15:08 - src.training.trainer - INFO - Epoch 19 - Train loss: 0.0142\n",
            "2025-08-14 22:15:08,764 - src.training.trainer - INFO - Epoch 19 - Validation loss: 0.0128\n",
            "2025-08-14 22:15:08 - src.training.trainer - INFO - Epoch 19 - Validation loss: 0.0128\n",
            "2025-08-14 22:15:08 - src.training.trainer - INFO - Epoch 19 - Validation loss: 0.0128\n",
            "2025-08-14 22:15:08,764 - src.training.metrics - INFO - Epoch 19 - Val metrics:\n",
            "2025-08-14 22:15:08 - src.training.metrics - INFO - Epoch 19 - Val metrics:\n",
            "2025-08-14 22:15:08 - src.training.metrics - INFO - Epoch 19 - Val metrics:\n",
            "2025-08-14 22:15:08,765 - src.training.metrics - INFO -   MAE: 0.0846\n",
            "2025-08-14 22:15:08 - src.training.metrics - INFO -   MAE: 0.0846\n",
            "2025-08-14 22:15:08 - src.training.metrics - INFO -   MAE: 0.0846\n",
            "2025-08-14 22:15:08,765 - src.training.metrics - INFO -   Correlation: 0.5483\n",
            "2025-08-14 22:15:08 - src.training.metrics - INFO -   Correlation: 0.5483\n",
            "2025-08-14 22:15:08 - src.training.metrics - INFO -   Correlation: 0.5483\n",
            "2025-08-14 22:15:08,765 - src.training.metrics - INFO -   Binary Accuracy: 0.9697\n",
            "2025-08-14 22:15:08 - src.training.metrics - INFO -   Binary Accuracy: 0.9697\n",
            "2025-08-14 22:15:08 - src.training.metrics - INFO -   Binary Accuracy: 0.9697\n",
            "2025-08-14 22:15:08,765 - src.training.metrics - INFO -   Binary F1: 0.9846\n",
            "2025-08-14 22:15:08 - src.training.metrics - INFO -   Binary F1: 0.9846\n",
            "2025-08-14 22:15:08 - src.training.metrics - INFO -   Binary F1: 0.9846\n",
            "2025-08-14 22:15:08,765 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:08 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:08 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:08,765 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:15:08 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:15:08 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:15:08,765 - src.training.trainer - INFO - No improvement for 3 evaluation steps.\n",
            "2025-08-14 22:15:08 - src.training.trainer - INFO - No improvement for 3 evaluation steps.\n",
            "2025-08-14 22:15:08 - src.training.trainer - INFO - No improvement for 3 evaluation steps.\n",
            "Epoch 20: 100% 75/75 [00:01<00:00, 66.64it/s, loss=0.0031]\n",
            "2025-08-14 22:15:09,891 - src.training.trainer - INFO - Epoch 20 - Train loss: 0.0136\n",
            "2025-08-14 22:15:09 - src.training.trainer - INFO - Epoch 20 - Train loss: 0.0136\n",
            "2025-08-14 22:15:09 - src.training.trainer - INFO - Epoch 20 - Train loss: 0.0136\n",
            "2025-08-14 22:15:10,179 - src.training.trainer - INFO - Epoch 20 - Validation loss: 0.0151\n",
            "2025-08-14 22:15:10 - src.training.trainer - INFO - Epoch 20 - Validation loss: 0.0151\n",
            "2025-08-14 22:15:10 - src.training.trainer - INFO - Epoch 20 - Validation loss: 0.0151\n",
            "2025-08-14 22:15:10,179 - src.training.metrics - INFO - Epoch 20 - Val metrics:\n",
            "2025-08-14 22:15:10 - src.training.metrics - INFO - Epoch 20 - Val metrics:\n",
            "2025-08-14 22:15:10 - src.training.metrics - INFO - Epoch 20 - Val metrics:\n",
            "2025-08-14 22:15:10,179 - src.training.metrics - INFO -   MAE: 0.0896\n",
            "2025-08-14 22:15:10 - src.training.metrics - INFO -   MAE: 0.0896\n",
            "2025-08-14 22:15:10 - src.training.metrics - INFO -   MAE: 0.0896\n",
            "2025-08-14 22:15:10,179 - src.training.metrics - INFO -   Correlation: 0.5486\n",
            "2025-08-14 22:15:10 - src.training.metrics - INFO -   Correlation: 0.5486\n",
            "2025-08-14 22:15:10 - src.training.metrics - INFO -   Correlation: 0.5486\n",
            "2025-08-14 22:15:10,179 - src.training.metrics - INFO -   Binary Accuracy: 0.9545\n",
            "2025-08-14 22:15:10 - src.training.metrics - INFO -   Binary Accuracy: 0.9545\n",
            "2025-08-14 22:15:10 - src.training.metrics - INFO -   Binary Accuracy: 0.9545\n",
            "2025-08-14 22:15:10,179 - src.training.metrics - INFO -   Binary F1: 0.9766\n",
            "2025-08-14 22:15:10 - src.training.metrics - INFO -   Binary F1: 0.9766\n",
            "2025-08-14 22:15:10 - src.training.metrics - INFO -   Binary F1: 0.9766\n",
            "2025-08-14 22:15:10,179 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:10 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:10 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:10,180 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:15:10 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:15:10 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:15:10,180 - src.training.trainer - INFO - No improvement for 4 evaluation steps.\n",
            "2025-08-14 22:15:10 - src.training.trainer - INFO - No improvement for 4 evaluation steps.\n",
            "2025-08-14 22:15:10 - src.training.trainer - INFO - No improvement for 4 evaluation steps.\n",
            "Epoch 21: 100% 75/75 [00:01<00:00, 68.27it/s, loss=0.0192]\n",
            "2025-08-14 22:15:11,346 - src.training.trainer - INFO - Epoch 21 - Train loss: 0.0147\n",
            "2025-08-14 22:15:11 - src.training.trainer - INFO - Epoch 21 - Train loss: 0.0147\n",
            "2025-08-14 22:15:11 - src.training.trainer - INFO - Epoch 21 - Train loss: 0.0147\n",
            "2025-08-14 22:15:11,636 - src.training.trainer - INFO - Epoch 21 - Validation loss: 0.0177\n",
            "2025-08-14 22:15:11 - src.training.trainer - INFO - Epoch 21 - Validation loss: 0.0177\n",
            "2025-08-14 22:15:11 - src.training.trainer - INFO - Epoch 21 - Validation loss: 0.0177\n",
            "2025-08-14 22:15:11,636 - src.training.metrics - INFO - Epoch 21 - Val metrics:\n",
            "2025-08-14 22:15:11 - src.training.metrics - INFO - Epoch 21 - Val metrics:\n",
            "2025-08-14 22:15:11 - src.training.metrics - INFO - Epoch 21 - Val metrics:\n",
            "2025-08-14 22:15:11,636 - src.training.metrics - INFO -   MAE: 0.0960\n",
            "2025-08-14 22:15:11 - src.training.metrics - INFO -   MAE: 0.0960\n",
            "2025-08-14 22:15:11 - src.training.metrics - INFO -   MAE: 0.0960\n",
            "2025-08-14 22:15:11,636 - src.training.metrics - INFO -   Correlation: 0.5412\n",
            "2025-08-14 22:15:11 - src.training.metrics - INFO -   Correlation: 0.5412\n",
            "2025-08-14 22:15:11 - src.training.metrics - INFO -   Correlation: 0.5412\n",
            "2025-08-14 22:15:11,636 - src.training.metrics - INFO -   Binary Accuracy: 0.9470\n",
            "2025-08-14 22:15:11 - src.training.metrics - INFO -   Binary Accuracy: 0.9470\n",
            "2025-08-14 22:15:11 - src.training.metrics - INFO -   Binary Accuracy: 0.9470\n",
            "2025-08-14 22:15:11,636 - src.training.metrics - INFO -   Binary F1: 0.9725\n",
            "2025-08-14 22:15:11 - src.training.metrics - INFO -   Binary F1: 0.9725\n",
            "2025-08-14 22:15:11 - src.training.metrics - INFO -   Binary F1: 0.9725\n",
            "2025-08-14 22:15:11,636 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:11 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:11 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:11,636 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:15:11 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:15:11 - src.training.metrics - INFO -   7-class F1: 0.9604\n",
            "2025-08-14 22:15:11,636 - src.training.trainer - INFO - No improvement for 5 evaluation steps.\n",
            "2025-08-14 22:15:11 - src.training.trainer - INFO - No improvement for 5 evaluation steps.\n",
            "2025-08-14 22:15:11 - src.training.trainer - INFO - No improvement for 5 evaluation steps.\n",
            "Epoch 22: 100% 75/75 [00:01<00:00, 67.59it/s, loss=0.0015]\n",
            "2025-08-14 22:15:12,747 - src.training.trainer - INFO - Epoch 22 - Train loss: 0.0142\n",
            "2025-08-14 22:15:12 - src.training.trainer - INFO - Epoch 22 - Train loss: 0.0142\n",
            "2025-08-14 22:15:12 - src.training.trainer - INFO - Epoch 22 - Train loss: 0.0142\n",
            "2025-08-14 22:15:13,052 - src.training.trainer - INFO - Epoch 22 - Validation loss: 0.0135\n",
            "2025-08-14 22:15:13 - src.training.trainer - INFO - Epoch 22 - Validation loss: 0.0135\n",
            "2025-08-14 22:15:13 - src.training.trainer - INFO - Epoch 22 - Validation loss: 0.0135\n",
            "2025-08-14 22:15:13,052 - src.training.metrics - INFO - Epoch 22 - Val metrics:\n",
            "2025-08-14 22:15:13 - src.training.metrics - INFO - Epoch 22 - Val metrics:\n",
            "2025-08-14 22:15:13 - src.training.metrics - INFO - Epoch 22 - Val metrics:\n",
            "2025-08-14 22:15:13,052 - src.training.metrics - INFO -   MAE: 0.0864\n",
            "2025-08-14 22:15:13 - src.training.metrics - INFO -   MAE: 0.0864\n",
            "2025-08-14 22:15:13 - src.training.metrics - INFO -   MAE: 0.0864\n",
            "2025-08-14 22:15:13,052 - src.training.metrics - INFO -   Correlation: 0.5459\n",
            "2025-08-14 22:15:13 - src.training.metrics - INFO -   Correlation: 0.5459\n",
            "2025-08-14 22:15:13 - src.training.metrics - INFO -   Correlation: 0.5459\n",
            "2025-08-14 22:15:13,052 - src.training.metrics - INFO -   Binary Accuracy: 0.9583\n",
            "2025-08-14 22:15:13 - src.training.metrics - INFO -   Binary Accuracy: 0.9583\n",
            "2025-08-14 22:15:13 - src.training.metrics - INFO -   Binary Accuracy: 0.9583\n",
            "2025-08-14 22:15:13,052 - src.training.metrics - INFO -   Binary F1: 0.9786\n",
            "2025-08-14 22:15:13 - src.training.metrics - INFO -   Binary F1: 0.9786\n",
            "2025-08-14 22:15:13 - src.training.metrics - INFO -   Binary F1: 0.9786\n",
            "2025-08-14 22:15:13,052 - src.training.metrics - INFO -   7-class Accuracy: 0.9773\n",
            "2025-08-14 22:15:13 - src.training.metrics - INFO -   7-class Accuracy: 0.9773\n",
            "2025-08-14 22:15:13 - src.training.metrics - INFO -   7-class Accuracy: 0.9773\n",
            "2025-08-14 22:15:13,052 - src.training.metrics - INFO -   7-class F1: 0.9728\n",
            "2025-08-14 22:15:13 - src.training.metrics - INFO -   7-class F1: 0.9728\n",
            "2025-08-14 22:15:13 - src.training.metrics - INFO -   7-class F1: 0.9728\n",
            "2025-08-14 22:15:13,052 - src.training.trainer - INFO - No improvement for 6 evaluation steps.\n",
            "2025-08-14 22:15:13 - src.training.trainer - INFO - No improvement for 6 evaluation steps.\n",
            "2025-08-14 22:15:13 - src.training.trainer - INFO - No improvement for 6 evaluation steps.\n",
            "Epoch 23: 100% 75/75 [00:01<00:00, 66.99it/s, loss=0.0003]\n",
            "2025-08-14 22:15:14,173 - src.training.trainer - INFO - Epoch 23 - Train loss: 0.0129\n",
            "2025-08-14 22:15:14 - src.training.trainer - INFO - Epoch 23 - Train loss: 0.0129\n",
            "2025-08-14 22:15:14 - src.training.trainer - INFO - Epoch 23 - Train loss: 0.0129\n",
            "2025-08-14 22:15:14,458 - src.training.trainer - INFO - Epoch 23 - Validation loss: 0.0137\n",
            "2025-08-14 22:15:14 - src.training.trainer - INFO - Epoch 23 - Validation loss: 0.0137\n",
            "2025-08-14 22:15:14 - src.training.trainer - INFO - Epoch 23 - Validation loss: 0.0137\n",
            "2025-08-14 22:15:14,458 - src.training.metrics - INFO - Epoch 23 - Val metrics:\n",
            "2025-08-14 22:15:14 - src.training.metrics - INFO - Epoch 23 - Val metrics:\n",
            "2025-08-14 22:15:14 - src.training.metrics - INFO - Epoch 23 - Val metrics:\n",
            "2025-08-14 22:15:14,458 - src.training.metrics - INFO -   MAE: 0.0864\n",
            "2025-08-14 22:15:14 - src.training.metrics - INFO -   MAE: 0.0864\n",
            "2025-08-14 22:15:14 - src.training.metrics - INFO -   MAE: 0.0864\n",
            "2025-08-14 22:15:14,458 - src.training.metrics - INFO -   Correlation: 0.5479\n",
            "2025-08-14 22:15:14 - src.training.metrics - INFO -   Correlation: 0.5479\n",
            "2025-08-14 22:15:14 - src.training.metrics - INFO -   Correlation: 0.5479\n",
            "2025-08-14 22:15:14,459 - src.training.metrics - INFO -   Binary Accuracy: 0.9621\n",
            "2025-08-14 22:15:14 - src.training.metrics - INFO -   Binary Accuracy: 0.9621\n",
            "2025-08-14 22:15:14 - src.training.metrics - INFO -   Binary Accuracy: 0.9621\n",
            "2025-08-14 22:15:14,459 - src.training.metrics - INFO -   Binary F1: 0.9806\n",
            "2025-08-14 22:15:14 - src.training.metrics - INFO -   Binary F1: 0.9806\n",
            "2025-08-14 22:15:14 - src.training.metrics - INFO -   Binary F1: 0.9806\n",
            "2025-08-14 22:15:14,459 - src.training.metrics - INFO -   7-class Accuracy: 0.9773\n",
            "2025-08-14 22:15:14 - src.training.metrics - INFO -   7-class Accuracy: 0.9773\n",
            "2025-08-14 22:15:14 - src.training.metrics - INFO -   7-class Accuracy: 0.9773\n",
            "2025-08-14 22:15:14,459 - src.training.metrics - INFO -   7-class F1: 0.9728\n",
            "2025-08-14 22:15:14 - src.training.metrics - INFO -   7-class F1: 0.9728\n",
            "2025-08-14 22:15:14 - src.training.metrics - INFO -   7-class F1: 0.9728\n",
            "2025-08-14 22:15:14,459 - src.training.trainer - INFO - No improvement for 7 evaluation steps.\n",
            "2025-08-14 22:15:14 - src.training.trainer - INFO - No improvement for 7 evaluation steps.\n",
            "2025-08-14 22:15:14 - src.training.trainer - INFO - No improvement for 7 evaluation steps.\n",
            "Epoch 24: 100% 75/75 [00:01<00:00, 69.37it/s, loss=0.0199]\n",
            "2025-08-14 22:15:15,541 - src.training.trainer - INFO - Epoch 24 - Train loss: 0.0136\n",
            "2025-08-14 22:15:15 - src.training.trainer - INFO - Epoch 24 - Train loss: 0.0136\n",
            "2025-08-14 22:15:15 - src.training.trainer - INFO - Epoch 24 - Train loss: 0.0136\n",
            "2025-08-14 22:15:15,825 - src.training.trainer - INFO - Epoch 24 - Validation loss: 0.0137\n",
            "2025-08-14 22:15:15 - src.training.trainer - INFO - Epoch 24 - Validation loss: 0.0137\n",
            "2025-08-14 22:15:15 - src.training.trainer - INFO - Epoch 24 - Validation loss: 0.0137\n",
            "2025-08-14 22:15:15,825 - src.training.metrics - INFO - Epoch 24 - Val metrics:\n",
            "2025-08-14 22:15:15 - src.training.metrics - INFO - Epoch 24 - Val metrics:\n",
            "2025-08-14 22:15:15 - src.training.metrics - INFO - Epoch 24 - Val metrics:\n",
            "2025-08-14 22:15:15,825 - src.training.metrics - INFO -   MAE: 0.0866\n",
            "2025-08-14 22:15:15 - src.training.metrics - INFO -   MAE: 0.0866\n",
            "2025-08-14 22:15:15 - src.training.metrics - INFO -   MAE: 0.0866\n",
            "2025-08-14 22:15:15,825 - src.training.metrics - INFO -   Correlation: 0.5269\n",
            "2025-08-14 22:15:15 - src.training.metrics - INFO -   Correlation: 0.5269\n",
            "2025-08-14 22:15:15 - src.training.metrics - INFO -   Correlation: 0.5269\n",
            "2025-08-14 22:15:15,825 - src.training.metrics - INFO -   Binary Accuracy: 0.9697\n",
            "2025-08-14 22:15:15 - src.training.metrics - INFO -   Binary Accuracy: 0.9697\n",
            "2025-08-14 22:15:15 - src.training.metrics - INFO -   Binary Accuracy: 0.9697\n",
            "2025-08-14 22:15:15,826 - src.training.metrics - INFO -   Binary F1: 0.9846\n",
            "2025-08-14 22:15:15 - src.training.metrics - INFO -   Binary F1: 0.9846\n",
            "2025-08-14 22:15:15 - src.training.metrics - INFO -   Binary F1: 0.9846\n",
            "2025-08-14 22:15:15,826 - src.training.metrics - INFO -   7-class Accuracy: 0.9811\n",
            "2025-08-14 22:15:15 - src.training.metrics - INFO -   7-class Accuracy: 0.9811\n",
            "2025-08-14 22:15:15 - src.training.metrics - INFO -   7-class Accuracy: 0.9811\n",
            "2025-08-14 22:15:15,826 - src.training.metrics - INFO -   7-class F1: 0.9759\n",
            "2025-08-14 22:15:15 - src.training.metrics - INFO -   7-class F1: 0.9759\n",
            "2025-08-14 22:15:15 - src.training.metrics - INFO -   7-class F1: 0.9759\n",
            "2025-08-14 22:15:15,826 - src.training.trainer - INFO - No improvement for 8 evaluation steps.\n",
            "2025-08-14 22:15:15 - src.training.trainer - INFO - No improvement for 8 evaluation steps.\n",
            "2025-08-14 22:15:15 - src.training.trainer - INFO - No improvement for 8 evaluation steps.\n",
            "Epoch 25: 100% 75/75 [00:01<00:00, 69.01it/s, loss=0.0189]\n",
            "2025-08-14 22:15:16,914 - src.training.trainer - INFO - Epoch 25 - Train loss: 0.0140\n",
            "2025-08-14 22:15:16 - src.training.trainer - INFO - Epoch 25 - Train loss: 0.0140\n",
            "2025-08-14 22:15:16 - src.training.trainer - INFO - Epoch 25 - Train loss: 0.0140\n",
            "2025-08-14 22:15:17,211 - src.training.trainer - INFO - Epoch 25 - Validation loss: 0.0131\n",
            "2025-08-14 22:15:17 - src.training.trainer - INFO - Epoch 25 - Validation loss: 0.0131\n",
            "2025-08-14 22:15:17 - src.training.trainer - INFO - Epoch 25 - Validation loss: 0.0131\n",
            "2025-08-14 22:15:17,212 - src.training.metrics - INFO - Epoch 25 - Val metrics:\n",
            "2025-08-14 22:15:17 - src.training.metrics - INFO - Epoch 25 - Val metrics:\n",
            "2025-08-14 22:15:17 - src.training.metrics - INFO - Epoch 25 - Val metrics:\n",
            "2025-08-14 22:15:17,212 - src.training.metrics - INFO -   MAE: 0.0875\n",
            "2025-08-14 22:15:17 - src.training.metrics - INFO -   MAE: 0.0875\n",
            "2025-08-14 22:15:17 - src.training.metrics - INFO -   MAE: 0.0875\n",
            "2025-08-14 22:15:17,212 - src.training.metrics - INFO -   Correlation: 0.5345\n",
            "2025-08-14 22:15:17 - src.training.metrics - INFO -   Correlation: 0.5345\n",
            "2025-08-14 22:15:17 - src.training.metrics - INFO -   Correlation: 0.5345\n",
            "2025-08-14 22:15:17,212 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:15:17 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:15:17 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:15:17,212 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:15:17 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:15:17 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:15:17,212 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:17 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:17 - src.training.metrics - INFO -   7-class Accuracy: 0.9735\n",
            "2025-08-14 22:15:17,212 - src.training.metrics - INFO -   7-class F1: 0.9699\n",
            "2025-08-14 22:15:17 - src.training.metrics - INFO -   7-class F1: 0.9699\n",
            "2025-08-14 22:15:17 - src.training.metrics - INFO -   7-class F1: 0.9699\n",
            "2025-08-14 22:15:17,212 - src.training.trainer - INFO - No improvement for 9 evaluation steps.\n",
            "2025-08-14 22:15:17 - src.training.trainer - INFO - No improvement for 9 evaluation steps.\n",
            "2025-08-14 22:15:17 - src.training.trainer - INFO - No improvement for 9 evaluation steps.\n",
            "Epoch 26: 100% 75/75 [00:01<00:00, 66.39it/s, loss=0.0257]\n",
            "2025-08-14 22:15:18,410 - src.training.trainer - INFO - Epoch 26 - Train loss: 0.0137\n",
            "2025-08-14 22:15:18 - src.training.trainer - INFO - Epoch 26 - Train loss: 0.0137\n",
            "2025-08-14 22:15:18 - src.training.trainer - INFO - Epoch 26 - Train loss: 0.0137\n",
            "2025-08-14 22:15:18,713 - src.training.trainer - INFO - Epoch 26 - Validation loss: 0.0146\n",
            "2025-08-14 22:15:18 - src.training.trainer - INFO - Epoch 26 - Validation loss: 0.0146\n",
            "2025-08-14 22:15:18 - src.training.trainer - INFO - Epoch 26 - Validation loss: 0.0146\n",
            "2025-08-14 22:15:18,713 - src.training.metrics - INFO - Epoch 26 - Val metrics:\n",
            "2025-08-14 22:15:18 - src.training.metrics - INFO - Epoch 26 - Val metrics:\n",
            "2025-08-14 22:15:18 - src.training.metrics - INFO - Epoch 26 - Val metrics:\n",
            "2025-08-14 22:15:18,713 - src.training.metrics - INFO -   MAE: 0.0945\n",
            "2025-08-14 22:15:18 - src.training.metrics - INFO -   MAE: 0.0945\n",
            "2025-08-14 22:15:18 - src.training.metrics - INFO -   MAE: 0.0945\n",
            "2025-08-14 22:15:18,713 - src.training.metrics - INFO -   Correlation: 0.5306\n",
            "2025-08-14 22:15:18 - src.training.metrics - INFO -   Correlation: 0.5306\n",
            "2025-08-14 22:15:18 - src.training.metrics - INFO -   Correlation: 0.5306\n",
            "2025-08-14 22:15:18,713 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:15:18 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:15:18 - src.training.metrics - INFO -   Binary Accuracy: 0.9659\n",
            "2025-08-14 22:15:18,713 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:15:18 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:15:18 - src.training.metrics - INFO -   Binary F1: 0.9827\n",
            "2025-08-14 22:15:18,713 - src.training.metrics - INFO -   7-class Accuracy: 0.9697\n",
            "2025-08-14 22:15:18 - src.training.metrics - INFO -   7-class Accuracy: 0.9697\n",
            "2025-08-14 22:15:18 - src.training.metrics - INFO -   7-class Accuracy: 0.9697\n",
            "2025-08-14 22:15:18,713 - src.training.metrics - INFO -   7-class F1: 0.9672\n",
            "2025-08-14 22:15:18 - src.training.metrics - INFO -   7-class F1: 0.9672\n",
            "2025-08-14 22:15:18 - src.training.metrics - INFO -   7-class F1: 0.9672\n",
            "2025-08-14 22:15:18,713 - src.training.trainer - INFO - No improvement for 10 evaluation steps.\n",
            "2025-08-14 22:15:18 - src.training.trainer - INFO - No improvement for 10 evaluation steps.\n",
            "2025-08-14 22:15:18 - src.training.trainer - INFO - No improvement for 10 evaluation steps.\n",
            "2025-08-14 22:15:18,713 - src.training.trainer - INFO - Early stopping at epoch 26\n",
            "2025-08-14 22:15:18 - src.training.trainer - INFO - Early stopping at epoch 26\n",
            "2025-08-14 22:15:18 - src.training.trainer - INFO - Early stopping at epoch 26\n",
            "2025-08-14 22:15:18,713 - src.training.trainer - INFO - Training completed. Best model found at epoch 16 with validation loss: 0.0127\n",
            "2025-08-14 22:15:18 - src.training.trainer - INFO - Training completed. Best model found at epoch 16 with validation loss: 0.0127\n",
            "2025-08-14 22:15:18 - src.training.trainer - INFO - Training completed. Best model found at epoch 16 with validation loss: 0.0127\n",
            "2025-08-14 22:15:18,715 - root - INFO - Training completed in 38.89 seconds\n",
            "2025-08-14 22:15:18 - root - INFO - Training completed in 38.89 seconds\n",
            "2025-08-14 22:15:18 - root - INFO - Training completed in 38.89 seconds\n",
            "Figure saved to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/logs/multimodal_training_curves.png\n",
            "Figure(1000x400)\n",
            "2025-08-14 22:15:19,136 - root - INFO - Evaluating on test set...\n",
            "2025-08-14 22:15:19 - root - INFO - Evaluating on test set...\n",
            "2025-08-14 22:15:19 - root - INFO - Evaluating on test set...\n",
            "2025-08-14 22:15:19,136 - src.training.trainer - INFO - Evaluating model on test set...\n",
            "2025-08-14 22:15:19 - src.training.trainer - INFO - Evaluating model on test set...\n",
            "2025-08-14 22:15:19 - src.training.trainer - INFO - Evaluating model on test set...\n",
            "2025-08-14 22:15:19,136 - src.training.trainer - INFO - Loading checkpoint from /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "2025-08-14 22:15:19 - src.training.trainer - INFO - Loading checkpoint from /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "2025-08-14 22:15:19 - src.training.trainer - INFO - Loading checkpoint from /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "2025-08-14 22:15:19,218 - src.training.trainer - INFO - Loaded checkpoint with best validation loss: 0.0127\n",
            "2025-08-14 22:15:19 - src.training.trainer - INFO - Loaded checkpoint with best validation loss: 0.0127\n",
            "2025-08-14 22:15:19 - src.training.trainer - INFO - Loaded checkpoint with best validation loss: 0.0127\n",
            "2025-08-14 22:15:19,427 - src.training.metrics - INFO - Test metrics:\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO - Test metrics:\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO - Test metrics:\n",
            "2025-08-14 22:15:19,427 - src.training.metrics - INFO -   MAE: 0.0859\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   MAE: 0.0859\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   MAE: 0.0859\n",
            "2025-08-14 22:15:19,427 - src.training.metrics - INFO -   Correlation: 0.5122\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   Correlation: 0.5122\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   Correlation: 0.5122\n",
            "2025-08-14 22:15:19,427 - src.training.metrics - INFO -   Binary Accuracy: 0.9544\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   Binary Accuracy: 0.9544\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   Binary Accuracy: 0.9544\n",
            "2025-08-14 22:15:19,427 - src.training.metrics - INFO -   Binary F1: 0.9767\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   Binary F1: 0.9767\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   Binary F1: 0.9767\n",
            "2025-08-14 22:15:19,428 - src.training.metrics - INFO -   7-class Accuracy: 0.9787\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   7-class Accuracy: 0.9787\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   7-class Accuracy: 0.9787\n",
            "2025-08-14 22:15:19,428 - src.training.metrics - INFO -   7-class F1: 0.9682\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   7-class F1: 0.9682\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   7-class F1: 0.9682\n",
            "2025-08-14 22:15:19,428 - src.training.metrics - INFO - Test metrics:\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO - Test metrics:\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO - Test metrics:\n",
            "2025-08-14 22:15:19,428 - src.training.metrics - INFO -   MAE: 0.0859\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   MAE: 0.0859\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   MAE: 0.0859\n",
            "2025-08-14 22:15:19,428 - src.training.metrics - INFO -   Correlation: 0.5122\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   Correlation: 0.5122\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   Correlation: 0.5122\n",
            "2025-08-14 22:15:19,428 - src.training.metrics - INFO -   Binary Accuracy: 0.9544\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   Binary Accuracy: 0.9544\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   Binary Accuracy: 0.9544\n",
            "2025-08-14 22:15:19,428 - src.training.metrics - INFO -   Binary F1: 0.9767\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   Binary F1: 0.9767\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   Binary F1: 0.9767\n",
            "2025-08-14 22:15:19,428 - src.training.metrics - INFO -   7-class Accuracy: 0.9787\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   7-class Accuracy: 0.9787\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   7-class Accuracy: 0.9787\n",
            "2025-08-14 22:15:19,428 - src.training.metrics - INFO -   7-class F1: 0.9682\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   7-class F1: 0.9682\n",
            "2025-08-14 22:15:19 - src.training.metrics - INFO -   7-class F1: 0.9682\n",
            "Scatter plot saved to /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/logs/multimodal_predictions.png\n",
            "Figure(800x800)\n",
            "2025-08-14 22:15:20,202 - root - INFO - Training and evaluation completed!\n",
            "2025-08-14 22:15:20 - root - INFO - Training and evaluation completed!\n",
            "2025-08-14 22:15:20 - root - INFO - Training and evaluation completed!\n",
            "\n",
            "===== Multimodal Sentiment Analysis Console =====\n",
            "1. Download and preprocess dataset\n",
            "2. Train a new model\n",
            "3. Evaluate a trained model\n",
            "4. Visualize training results\n",
            "5. Exit\n",
            "=================================================\n",
            "Enter your choice (1-5): 3\n",
            "\n",
            "===== Multimodal Sentiment Analysis Console =====\n",
            "1. Download and preprocess dataset\n",
            "2. Train a new model\n",
            "3. Evaluate a trained model\n",
            "4. Visualize training results\n",
            "5. Exit\n",
            "=================================================\n",
            "Enter your choice (1-5): 4\n",
            "\n",
            "===== Multimodal Sentiment Analysis Console =====\n",
            "1. Download and preprocess dataset\n",
            "2. Train a new model\n",
            "3. Evaluate a trained model\n",
            "4. Visualize training results\n",
            "5. Exit\n",
            "=================================================\n",
            "Enter your choice (1-5): 5\n",
            "2025-08-14 22:17:13,061 - __main__ - INFO - Exiting the console. Goodbye!\n",
            "2025-08-14 22:17:13 - __main__ - INFO - Exiting the console. Goodbye!\n",
            "2025-08-14 22:17:13 - __main__ - INFO - Exiting the console. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile inference.py\n",
        "# inference.py\n",
        "import os\n",
        "import sys\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer, BertModel, pipeline\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "# Add project root to path for our model imports\n",
        "sys.path.append(str(Path(__file__).resolve().parent))\n",
        "\n",
        "from src.models.fusion import TransformerFusionModel\n",
        "from config import (\n",
        "    TEXT_EMBEDDING_DIM, HIDDEN_DIM, NUM_ATTENTION_HEADS,\n",
        "    NUM_TRANSFORMER_LAYERS, DROPOUT_RATE\n",
        ")\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# --- Feature Extraction Functions ---\n",
        "\n",
        "def extract_audio_from_video(video_path, audio_output_path):\n",
        "    \"\"\"Extracts audio from a video file and saves it as WAV.\"\"\"\n",
        "    try:\n",
        "        logger.info(f\"Extracting audio from {video_path}...\")\n",
        "        video_clip = VideoFileClip(str(video_path))\n",
        "        audio_clip = video_clip.audio\n",
        "        if audio_clip is None:\n",
        "            logger.error(f\"No audio track found in {video_path}\")\n",
        "            return False\n",
        "        audio_clip.write_audiofile(str(audio_output_path), codec='pcm_s16le', logger=None)\n",
        "        video_clip.close()\n",
        "        logger.info(f\"Audio saved to {audio_output_path}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to extract audio from {video_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "def get_transcript_from_audio(audio_path):\n",
        "    \"\"\"Generates a transcript from an audio file using Whisper.\"\"\"\n",
        "    try:\n",
        "        logger.info(f\"Transcribing audio from {audio_path}...\")\n",
        "        # Use a smaller, faster model for quicker inference. Use 'openai/whisper-large-v3' for higher accuracy.\n",
        "        pipe = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base\", device=DEVICE)\n",
        "        result = pipe(str(audio_path))\n",
        "        transcript = result['text'].strip()\n",
        "        logger.info(f\"Transcript: '{transcript[:100]}...'\")\n",
        "        return transcript\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to transcribe audio {audio_path}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def get_text_embedding(text, tokenizer, bert_model, device):\n",
        "    \"\"\"Converts raw text to a BERT [CLS] embedding.\"\"\"\n",
        "    try:\n",
        "        inputs = tokenizer(\n",
        "            text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=512,  # Standard BERT max length\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = bert_model(**inputs)\n",
        "            embedding = outputs.last_hidden_state[:, 0, :].cpu()\n",
        "        return embedding\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to create text embedding: {e}\")\n",
        "        return torch.zeros(1, TEXT_EMBEDDING_DIM)\n",
        "\n",
        "# --- Main Inference Logic ---\n",
        "\n",
        "def run_inference():\n",
        "    \"\"\"\n",
        "    Main function to run inference on a directory of video files.\n",
        "    \"\"\"\n",
        "    global DEVICE # Use the globally determined device\n",
        "\n",
        "    # 1. Get user input\n",
        "    model_path_str = input(\"Enter the path to your trained model checkpoint (.pt): \").strip()\n",
        "    video_dir_str = input(\"Enter the path to the directory containing your .mp4 files: \").strip()\n",
        "\n",
        "    model_path = Path(model_path_str)\n",
        "    video_dir = Path(video_dir_str)\n",
        "\n",
        "    if not model_path.exists():\n",
        "        logger.error(f\"Model checkpoint not found: {model_path}\")\n",
        "        return\n",
        "    if not video_dir.is_dir():\n",
        "        logger.error(f\"Video directory not found: {video_dir}\")\n",
        "        return\n",
        "\n",
        "    # 2. Setup Device\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    logger.info(f\"Using device: {DEVICE}\")\n",
        "\n",
        "    # 3. Load the trained model\n",
        "    logger.info(\"Loading trained model...\")\n",
        "    model = TransformerFusionModel(\n",
        "        text_dim=TEXT_EMBEDDING_DIM,\n",
        "        audio_dim=0, # Not used in text-only\n",
        "        visual_dim=0, # Not used in text-only\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        num_layers=NUM_TRANSFORMER_LAYERS,\n",
        "        num_heads=NUM_ATTENTION_HEADS,\n",
        "        dropout_rate=DROPOUT_RATE\n",
        "    )\n",
        "    checkpoint = torch.load(model_path, map_location=DEVICE)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    logger.info(\"Model loaded successfully.\")\n",
        "\n",
        "    # 4. Load the feature extractor (BERT)\n",
        "    logger.info(\"Loading BERT model for feature extraction...\")\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    bert_model = BertModel.from_pretrained(\"bert-base-uncased\").to(DEVICE)\n",
        "    bert_model.eval()\n",
        "\n",
        "    # 5. Process each video file\n",
        "    video_files = list(video_dir.glob(\"*.mp4\"))\n",
        "    if not video_files:\n",
        "        logger.error(f\"No .mp4 files found in {video_dir}\")\n",
        "        return\n",
        "\n",
        "    predictions_data = []\n",
        "    temp_dir = Path(\"./temp_audio\")\n",
        "    temp_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    for video_path in tqdm(video_files, desc=\"Processing Videos\"):\n",
        "        video_id = video_path.stem\n",
        "        temp_audio_path = temp_dir / f\"{video_id}.wav\"\n",
        "\n",
        "        # Step A: Extract Audio\n",
        "        if not extract_audio_from_video(video_path, temp_audio_path):\n",
        "            continue\n",
        "\n",
        "        # Step B: Get Transcript\n",
        "        transcript = get_transcript_from_audio(temp_audio_path)\n",
        "        if not transcript:\n",
        "            logger.warning(f\"Skipping video {video_id} due to empty transcript.\")\n",
        "            continue\n",
        "\n",
        "        # Step C: Get Text Embedding\n",
        "        text_embedding = get_text_embedding(transcript, tokenizer, bert_model, DEVICE)\n",
        "\n",
        "        # Step D: Prepare input for the model\n",
        "        model_input = {\"language\": text_embedding.to(DEVICE)}\n",
        "\n",
        "        # Step E: Get Prediction\n",
        "        with torch.no_grad():\n",
        "            prediction = model(model_input)\n",
        "            sentiment_score = prediction.item()\n",
        "\n",
        "        logger.info(f\"Video: {video_path.name}, Predicted Sentiment: {sentiment_score:.4f}\")\n",
        "        predictions_data.append({\"ID\": video_path.name, \"Label\": sentiment_score})\n",
        "\n",
        "        # Clean up temporary audio file\n",
        "        os.remove(temp_audio_path)\n",
        "\n",
        "    # 6. Save results to CSV\n",
        "    if predictions_data:\n",
        "        df = pd.DataFrame(predictions_data)\n",
        "        output_csv_path = video_dir / \"predictions.csv\"\n",
        "        df.to_csv(output_csv_path, index=False)\n",
        "        logger.info(f\"Inference complete! Predictions saved to {output_csv_path}\")\n",
        "    else:\n",
        "        logger.warning(\"No predictions were made.\")\n",
        "\n",
        "    # Clean up temp directory\n",
        "    os.rmdir(temp_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_inference()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4It9Y5qqLn8",
        "outputId": "6616edc3-7053-47fb-9591-f90a1f2694cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing inference.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdDjl6Vur9y8",
        "outputId": "c22abb80-1189-4ffe-f6cb-ba1637d8935f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-14 22:36:16.683546: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-08-14 22:36:16.703367: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1755210976.725327   35467 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1755210976.731922   35467 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1755210976.749791   35467 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755210976.749823   35467 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755210976.749826   35467 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755210976.749829   35467 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-14 22:36:16.754808: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "error: XDG_RUNTIME_DIR not set in the environment.\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "Enter the path to your trained model checkpoint (.pt): /content/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset/models/multimodal_fusion_best.pt\n",
            "Enter the path to the directory containing your .mp4 files: /content\n",
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n",
            "\n",
            "Processing Videos:   0% 0/4 [00:00<?, ?it/s]Device set to use cuda\n",
            "`return_token_timestamps` is deprecated for WhisperFeatureExtractor and will be removed in Transformers v5. Use `return_attention_mask` instead, as the number of frames can be inferred from it.\n",
            "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
            "Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.\n",
            "Processing Videos:  25% 1/4 [00:02<00:06,  2.29s/it]Device set to use cuda\n",
            "Processing Videos:  50% 2/4 [00:03<00:03,  1.71s/it]Device set to use cuda\n",
            "Processing Videos:  75% 3/4 [00:04<00:01,  1.50s/it]Device set to use cuda\n",
            "Processing Videos: 100% 4/4 [00:06<00:00,  1.55s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('/content/predictions.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "hga7krT6s3GC",
        "outputId": "920114ef-5ec8-46e9-d260-fcd88dfe7229"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       ID     Label\n",
              "0  validate_video_001.mp4  0.188300\n",
              "1  validate_video_004.mp4  0.240068\n",
              "2  validate_video_002.mp4  0.204071\n",
              "3  validate_video_003.mp4  0.180675"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-014b3e19-a541-4d7d-bd12-02c0944a0a51\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>validate_video_001.mp4</td>\n",
              "      <td>0.188300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>validate_video_004.mp4</td>\n",
              "      <td>0.240068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>validate_video_002.mp4</td>\n",
              "      <td>0.204071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>validate_video_003.mp4</td>\n",
              "      <td>0.180675</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-014b3e19-a541-4d7d-bd12-02c0944a0a51')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-014b3e19-a541-4d7d-bd12-02c0944a0a51 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-014b3e19-a541-4d7d-bd12-02c0944a0a51');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7f75f9cf-c6b2-47f5-8079-1c6e7650fecf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7f75f9cf-c6b2-47f5-8079-1c6e7650fecf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7f75f9cf-c6b2-47f5-8079-1c6e7650fecf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"validate_video_004.mp4\",\n          \"validate_video_003.mp4\",\n          \"validate_video_001.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.026390449626826212,\n        \"min\": 0.1806747168302536,\n        \"max\": 0.2400677055120468,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.2400677055120468,\n          0.1806747168302536,\n          0.1882997304201126\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tXZaoVFRs8lU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}